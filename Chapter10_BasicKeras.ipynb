{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup\n",
    "\n",
    "Importing modules, making sure that we are using python 3, sklearn 0.20 or up, and tensorflow 2.x.\n",
    "\n",
    "The code also sets up the matplolib figure sizesb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "#Tensorflow >= 2.0 required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "#Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#for the same output as the book\n",
    "np.random.seed(42)\n",
    "\n",
    "# to plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize = 14)\n",
    "mpl.rc('xtick', labelsize = 12)\n",
    "mpl.rc('ytick', labelsize = 12)\n",
    "\n",
    "# Where to save figures\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = 'ann'\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, 'images', CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok = True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True,fig_extension=\"png\",\n",
    "            resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "\n",
    "setting max_iter and tol explicitly avoids warnings about an impending change to their default value in future Scikit-learn versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter = 1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X,y)\n",
    "\n",
    "y_pred = per_clf.predict([[2,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure perceptron_iris_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0,5,0,2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "    np.linspace(axes[0], axes[1], 500).reshape(-1,1),\n",
    "    np.linspace(axes[2], axes[3], 200).reshape(-1,1),\n",
    ")\n",
    "X_new = np.c_[x0.ravel(),x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(X[y==0,0],X[y==0,1],\"bs\",label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1,0],X[y==1,1],\"yo\",label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]],\n",
    "         [a * axes[0] + b, a * axes[1] + b],\"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0,x1,zz,cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal Length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize = 14)\n",
    "plt.axis(axes)\n",
    "\n",
    "save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "The reason for the activation functions is that otherwise there will be no Gradient Descent for the step function. \n",
    "\n",
    "The sigmoid function has a well-defined nonzero derivative at all values, allowing for progress with Gradient Descent.\n",
    "\n",
    "The tanh function ranges from -1 to 1 instead of 0 to 1 like the sigmoid. Being centered around 0 at initialization helps speed up convergence.\n",
    "\n",
    "The relu function is continuous but has no slope at z = 0, this can make Gradient Descent bounce around, and its derivative is 0 for z < 0. It however is fast to compute and doesn't have a maximum value which helps with some issues in Gradient Descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "# Finite difference approximation of derivation\n",
    "# Also called Newton's difference quotient\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5,5,200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z,np.sign(z),\"r-\",linewidth=1,label=\"Step\")\n",
    "plt.plot(z,sigmoid(z),\"g--\",linewidth=2,label=\"Sigmoid\")\n",
    "plt.plot(z,np.tanh(z),\"b-\",linewidth=2,label=\"Tanh\")\n",
    "plt.plot(z,relu(z),\"m-.\",linewidth=2,label='ReLu')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\",fontsize=14)\n",
    "plt.axis([-5,5,-1.2,1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign,z), \"r-\",linewidth=1,label=\"Step\")\n",
    "plt.plot(0,0,'ro',markersize=5)\n",
    "plt.plot(0,0,'rx',markersize=10)\n",
    "plt.plot(z, derivative(sigmoid,z),\"g--\",linewidth=2,label=\"Sigmoid\")\n",
    "plt.plot(z, derivative(np.tanh,z),\"b-\",linewidth=2,label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu,z),\"m-.\",linewidth=2,label=\"ReLu\")\n",
    "#plt.grid shows the grid behind the graph\n",
    "plt.grid(True)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5,5,-0.2,1.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Multilayer Perceptrons\n",
    "\n",
    "To use perceptrons for regression, all thats needed is to have one output neuron per dimension.\n",
    "\n",
    "Dont use activation functions so that output can be in any range of values. \n",
    "\n",
    "If you want to guarantee the output will be positive, you can use ReLu on the final layer (softplus is a smooth variant, softplus(z) = log(1 + exp(z)), that can be an alternative).\n",
    "\n",
    "If the output needs to be in a certain range of values use either the logistic function or hyperbolic tangent and then scale the labels to the appropriate range. (0, 1) logitistic, (-1,1) tangent.\n",
    "\n",
    "The *Loss* function typically is MSE, mean squared error, but if there are many outliers, might use mean absolute error, MAE. Or even Huber loss, which uses both.\n",
    "\n",
    "Huber loss: Is quadratic when the error is smaller than a threshold *X* (typically 1) but linear when the error is larger than *X*. The linear part makes it less sensitive to outliers than MSE and the quadratic part allows it to converge faster and be more precise than MAE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with MLP's\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fashion MNIST dataset in Keras comes already split\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60,000 images, each 28x28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel intensity is represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting full training set into a validation set and (smaller) training set. We also scale the pixel intensities down to the 0-1 range an convert them to floats, by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] /255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting an image with matplotlib imshow() function using the 'binary' color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[4], cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the corresponding class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validatoin set has 5000 images, an the test set has 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols*1.2, n_rows*1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows,n_cols,index+1)\n",
    "        #interpolation determines img quality\n",
    "        plt.imshow(X_train[index], cmap='binary',interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1a5748ebe0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a5748ed68>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a5748efd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a5749b358>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model,\"my_fashion_mnist_model.png\",\n",
    "                      show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights have been initialized randomly to break symmetry, and the biaes set to zero. If I want to set a different initialization method, have to set the kernel_initializer or bias_initializer for each layer. \n",
    "\n",
    "Kernel is a name for matrix of connection weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights,biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to:\n",
    "\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[keras.metrics.sparse_categorical_accuracy]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7237 - accuracy: 0.7643 - val_loss: 0.5213 - val_accuracy: 0.8226\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4843 - accuracy: 0.8317 - val_loss: 0.4350 - val_accuracy: 0.8536\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4392 - accuracy: 0.8456 - val_loss: 0.5355 - val_accuracy: 0.7970\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4123 - accuracy: 0.8566 - val_loss: 0.3919 - val_accuracy: 0.8650\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3937 - accuracy: 0.8618 - val_loss: 0.3741 - val_accuracy: 0.8686\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3750 - accuracy: 0.8675 - val_loss: 0.3720 - val_accuracy: 0.8730\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3632 - accuracy: 0.8715 - val_loss: 0.3614 - val_accuracy: 0.8708\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3518 - accuracy: 0.8750 - val_loss: 0.3864 - val_accuracy: 0.8624\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3413 - accuracy: 0.8787 - val_loss: 0.3588 - val_accuracy: 0.8712\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3318 - accuracy: 0.8826 - val_loss: 0.3422 - val_accuracy: 0.8780\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3237 - accuracy: 0.8840 - val_loss: 0.3441 - val_accuracy: 0.8782\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3146 - accuracy: 0.8869 - val_loss: 0.3314 - val_accuracy: 0.8824\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3078 - accuracy: 0.8893 - val_loss: 0.3275 - val_accuracy: 0.8868\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3018 - accuracy: 0.8916 - val_loss: 0.3404 - val_accuracy: 0.8774\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2943 - accuracy: 0.8933 - val_loss: 0.3224 - val_accuracy: 0.8856\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2889 - accuracy: 0.8966 - val_loss: 0.3087 - val_accuracy: 0.8894\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2836 - accuracy: 0.8978 - val_loss: 0.3556 - val_accuracy: 0.8730\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2773 - accuracy: 0.9005 - val_loss: 0.3138 - val_accuracy: 0.8896\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2727 - accuracy: 0.9021 - val_loss: 0.3123 - val_accuracy: 0.8902\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2671 - accuracy: 0.9034 - val_loss: 0.3282 - val_accuracy: 0.8810\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2622 - accuracy: 0.9057 - val_loss: 0.3056 - val_accuracy: 0.8940\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2575 - accuracy: 0.9073 - val_loss: 0.2973 - val_accuracy: 0.8974\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2534 - accuracy: 0.9081 - val_loss: 0.2996 - val_accuracy: 0.8930\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2482 - accuracy: 0.9100 - val_loss: 0.3084 - val_accuracy: 0.8876\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2442 - accuracy: 0.9121 - val_loss: 0.2962 - val_accuracy: 0.8942\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2403 - accuracy: 0.9135 - val_loss: 0.3061 - val_accuracy: 0.8900\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2360 - accuracy: 0.9156 - val_loss: 0.3010 - val_accuracy: 0.8960\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2326 - accuracy: 0.9159 - val_loss: 0.2984 - val_accuracy: 0.8944\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2283 - accuracy: 0.9183 - val_loss: 0.3065 - val_accuracy: 0.8898\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2248 - accuracy: 0.9192 - val_loss: 0.3028 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tips:\n",
    "\n",
    "Instead of using the `validation_data` argument, set `validation_split` to the ratio that you want to usefor validation. It will use the last, say 10%, of the data (before shuffling) for validation\n",
    "\n",
    "If the training set is skewed, the `class_weight` argument can let the fit method know and Keras will compute loss accordingly.\n",
    "\n",
    "If per-instance weight is needed, use `sample_weight`.\n",
    "If both `class_weight` and `sample_weight` are provided, they will be multiplied. Per-instance weights are useful if for example, some data was labelled by experts and others not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-50ecdfdc7132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set is computed at the end of each epoch, while training set is computed during each epoch, which accounts for their difference at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3372 - accuracy: 0.8825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33723148703575134, 0.8824999928474426]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96],\n",
       "       [0.  , 0.  , 0.98, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-41-81ace37e545f>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2,2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1,3, index+1)\n",
    "    plt.imshow(image,cmap='binary',interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation=\"relu\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data = (X_valid,y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38856643],\n",
       "       [1.6792021 ],\n",
       "       [3.1022797 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "\n",
    "This is a *Wide and Deep* network using the Functional API. It sends the input data along the hidden layers but also on a different route straight to the concat layer to capture simple patterns as well the complex ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_,hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 30)           270         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 30)           930         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 38)           0           input_3[0][0]                    \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            39          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8422 - val_loss: 1.7479\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7258 - val_loss: 0.7584\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6472 - val_loss: 0.6156\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5944 - val_loss: 0.5442\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5538 - val_loss: 0.5013\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5217 - val_loss: 0.4749\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4970 - val_loss: 0.4519\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4784 - val_loss: 0.4399\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.4288\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4316\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4425 - val_loss: 0.4132\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4348 - val_loss: 0.4353\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4287 - val_loss: 0.4309\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4232 - val_loss: 0.4025\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4185 - val_loss: 0.4114\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4002\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4188\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.4173\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4039 - val_loss: 0.3970\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4013 - val_loss: 0.4554\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4004\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_valid,y_valid))\n",
    "mse_test = model.evaluate(X_test,y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to send different subsets of input features through the wide or deep paths:\n",
    "\n",
    "In this example, 5 features(features 0 to 4) go through the wide path and 6 features(features 2 to 7) through the deep path. There is overlap in features 2,3,4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A,hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                          outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8145 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6771 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5979 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5584 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5334 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5120 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4970 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4843 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4730 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4644 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4570 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4510 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4421 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4385 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4305 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4274 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4204\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4219\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B),y_train, epochs=20,\n",
    "                    validation_data = ((X_valid_A,X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A,X_test_B), y_test)\n",
    "\n",
    "y_pred = model.predict((X_new_A,X_new_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cases for multiple outputs:\n",
    "\n",
    "- The task may demand it. Example, locating the main object in a picture. That is both a regression(locate coordinates of objects center) and classification.\n",
    "- Multiple independent tasks. The network can learn features that are useful across tasks.\n",
    "- A regularization technique. Adding auxilary outputs to ensure that so that the underlying part of the network learns something on its own, without relying on the rest of the network (???? not sure how this regularizes...) In the diagram of the network, it would be auxiliary outputing at the step where the multiple inputs are concatanated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A,hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1,name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output,aux_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\",\"mse\"], loss_weights=[0.9,0.1],optimizer=\"sgd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8602 - main_output_loss: 0.7458 - aux_output_loss: 1.8899 - val_loss: 5.9702 - val_main_output_loss: 6.3391 - val_aux_output_loss: 2.6507\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5736 - main_output_loss: 0.5210 - aux_output_loss: 1.0469 - val_loss: 1.4693 - val_main_output_loss: 1.3954 - val_aux_output_loss: 2.1342\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5078 - main_output_loss: 0.4649 - aux_output_loss: 0.8936 - val_loss: 1.8651 - val_main_output_loss: 1.9608 - val_aux_output_loss: 1.0039\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4619 - main_output_loss: 0.4275 - aux_output_loss: 0.7711 - val_loss: 0.4492 - val_main_output_loss: 0.4084 - val_aux_output_loss: 0.8163\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4417 - main_output_loss: 0.4131 - aux_output_loss: 0.6997 - val_loss: 0.4053 - val_main_output_loss: 0.3770 - val_aux_output_loss: 0.6597\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4254 - main_output_loss: 0.4002 - aux_output_loss: 0.6521 - val_loss: 0.4129 - val_main_output_loss: 0.3882 - val_aux_output_loss: 0.6356\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4280 - main_output_loss: 0.4065 - aux_output_loss: 0.6216 - val_loss: 0.4002 - val_main_output_loss: 0.3799 - val_aux_output_loss: 0.5827\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4104 - main_output_loss: 0.3898 - aux_output_loss: 0.5954 - val_loss: 0.3866 - val_main_output_loss: 0.3667 - val_aux_output_loss: 0.5659\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4027 - main_output_loss: 0.3832 - aux_output_loss: 0.5776 - val_loss: 0.3858 - val_main_output_loss: 0.3656 - val_aux_output_loss: 0.5676\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3987 - main_output_loss: 0.3801 - aux_output_loss: 0.5663 - val_loss: 0.3727 - val_main_output_loss: 0.3524 - val_aux_output_loss: 0.5557\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4000 - main_output_loss: 0.3828 - aux_output_loss: 0.5543 - val_loss: 0.3656 - val_main_output_loss: 0.3454 - val_aux_output_loss: 0.5475\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3943 - main_output_loss: 0.3774 - aux_output_loss: 0.5460 - val_loss: 0.3643 - val_main_output_loss: 0.3424 - val_aux_output_loss: 0.5610\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3973 - main_output_loss: 0.3815 - aux_output_loss: 0.5394 - val_loss: 0.3563 - val_main_output_loss: 0.3362 - val_aux_output_loss: 0.5371\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3838 - main_output_loss: 0.3675 - aux_output_loss: 0.5311 - val_loss: 0.3555 - val_main_output_loss: 0.3359 - val_aux_output_loss: 0.5319\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3850 - main_output_loss: 0.3699 - aux_output_loss: 0.5214 - val_loss: 0.3613 - val_main_output_loss: 0.3446 - val_aux_output_loss: 0.5118\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3785 - main_output_loss: 0.3631 - aux_output_loss: 0.5176 - val_loss: 0.3531 - val_main_output_loss: 0.3351 - val_aux_output_loss: 0.5152\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3777 - main_output_loss: 0.3628 - aux_output_loss: 0.5115 - val_loss: 0.3595 - val_main_output_loss: 0.3366 - val_aux_output_loss: 0.5649\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3719 - main_output_loss: 0.3571 - aux_output_loss: 0.5043 - val_loss: 0.3481 - val_main_output_loss: 0.3314 - val_aux_output_loss: 0.4979\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3911 - main_output_loss: 0.3783 - aux_output_loss: 0.5064 - val_loss: 0.3481 - val_main_output_loss: 0.3303 - val_aux_output_loss: 0.5077\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3700 - main_output_loss: 0.3559 - aux_output_loss: 0.4963 - val_loss: 0.3422 - val_main_output_loss: 0.3246 - val_aux_output_loss: 0.5008\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A,X_train_B],[y_train,y_train],\n",
    "                   epochs=20, validation_data=([X_valid_A,X_valid_B],[y_valid,y_valid]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3608 - main_output_loss: 0.3480 - aux_output_loss: 0.4754\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "[X_test_A,X_test_B], [y_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A,X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Subclassing API\n",
    "\n",
    "The Sequential and Functional API are great for analysis and ease of reading but they are static. For more dynamic behaviours, use Subclassing API.\n",
    "\n",
    "Pros:\n",
    "- Flexibility and dynamic behaviour\n",
    "\n",
    "Cons:\n",
    "- Model archeticture is hidden in call() method so Keras cant easily inspect it\n",
    "- Cannot save or clone it\n",
    "- summary() method only return layers and not how they're connected\n",
    "- Keras cannot check shapes and types, so easier to make a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30,activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units,activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units,activation=activation)\n",
    "        self.main_output =keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "   \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A,hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.3298 - output_1_loss: 2.2186 - output_2_loss: 3.3304 - val_loss: 2.1435 - val_output_1_loss: 1.1581 - val_output_2_loss: 11.0117\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.9714 - output_1_loss: 0.8543 - output_2_loss: 2.0252 - val_loss: 1.7567 - val_output_1_loss: 0.8205 - val_output_2_loss: 10.1825\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8268 - output_1_loss: 0.7289 - output_2_loss: 1.7082 - val_loss: 1.5664 - val_output_1_loss: 0.7913 - val_output_2_loss: 8.5419\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7636 - output_1_loss: 0.6764 - output_2_loss: 1.5477 - val_loss: 1.3088 - val_output_1_loss: 0.6549 - val_output_2_loss: 7.1933\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7211 - output_1_loss: 0.6402 - output_2_loss: 1.4489 - val_loss: 1.1357 - val_output_1_loss: 0.5964 - val_output_2_loss: 5.9898\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6895 - output_1_loss: 0.6124 - output_2_loss: 1.3833 - val_loss: 1.0036 - val_output_1_loss: 0.5937 - val_output_2_loss: 4.6933\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6632 - output_1_loss: 0.5894 - output_2_loss: 1.3274 - val_loss: 0.8904 - val_output_1_loss: 0.5591 - val_output_2_loss: 3.8714\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6410 - output_1_loss: 0.5701 - output_2_loss: 1.2796 - val_loss: 0.8009 - val_output_1_loss: 0.5243 - val_output_2_loss: 3.2903\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6204 - output_1_loss: 0.5514 - output_2_loss: 1.2416 - val_loss: 0.7357 - val_output_1_loss: 0.5144 - val_output_2_loss: 2.7275\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6024 - output_1_loss: 0.5355 - output_2_loss: 1.2043 - val_loss: 0.6849 - val_output_1_loss: 0.5014 - val_output_2_loss: 2.3370\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5841 - output_1_loss: 0.5188 - output_2_loss: 1.1722\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',loss_weights=[0.9,0.1],\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train,y_train), epochs=10,\n",
    "                   validation_data=((X_valid_A,X_valid_B),(y_valid,y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A,X_test_B),\n",
    "                                                (y_test,y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A,X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train,y_train,epochs=10,\n",
    "                   validation_data=(X_valid,y_valid))\n",
    "mse_test= model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5400236],\n",
       "       [1.6505971],\n",
       "       [3.0098243]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1a644e8f60>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")\n",
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks during Training\n",
    "\n",
    "Callbacks let you specify a list of objects that Keras will call at the start and end of training, at the start and end of an epochj, and even before and after processing each batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This callback, ModelCheckpoint, saves checkpoints during training, at the end of each epoch and regular intervals. We can also have it save only up to the point of the best model with, `save_best_only=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 992us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                               save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])\n",
    "# it will roll back to the best model\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I otherwise want to stop training early after no measurable increase in validation set, use `callbacks.EarlyStopping`, setting the `patience` to the number of epochs that the training has seen no improvement. They can be combiined to save everything, `callbacks.ModelCheckpoint` in case computer crashes and `callbacks.EarlyStopping` to avoid wasting time and resources.\n",
    "\n",
    "You can set the number of epochs higher since it will stop on its own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4110\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.3996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4201 - val_loss: 0.3939\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4154 - val_loss: 0.3889\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.3746\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3976 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3661\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.3631\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3625\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3810 - val_loss: 0.3592\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3563\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3766 - val_loss: 0.3535\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3732 - val_loss: 0.3512\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.3699\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3476\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3527\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3658 - val_loss: 0.3700\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3647 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3592\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.3521\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.3626\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3431\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3374\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3573\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3530 - val_loss: 0.3425\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3369\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3515 - val_loss: 0.3515\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3426\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3564\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3481 - val_loss: 0.3457\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3433\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3659\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3286\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3460 - val_loss: 0.3268\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3439\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3263\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3444 - val_loss: 0.3910\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3439 - val_loss: 0.3275\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3435 - val_loss: 0.3561\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3430 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3242\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3765\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.3289\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3502\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3456\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3445\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3387 - val_loss: 0.3351\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3566\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3257\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3348\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3365 - val_loss: 0.3560\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3361 - val_loss: 0.3583\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3357 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3351 - val_loss: 0.3203\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3840\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3233\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3476\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3407\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.3462\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3332 - val_loss: 0.3347\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3354\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.3274\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3167\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3317 - val_loss: 0.3280\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3312 - val_loss: 0.3634\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3310 - val_loss: 0.3176\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3308 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3305 - val_loss: 0.3529\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3299 - val_loss: 0.3258\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3294 - val_loss: 0.3630\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3296 - val_loss: 0.3376\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3291 - val_loss: 0.3211\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3287 - val_loss: 0.3456\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3285 - val_loss: 0.3158\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3281 - val_loss: 0.3409\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.3379\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3273 - val_loss: 0.3213\n",
      "162/162 [==============================] - 0s 879us/step - loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also create custome callbacks. The naming convention here uses `on_train/test/predict_begin/end()` in the function. The full options are in the documentation.\n",
    "\n",
    "These are good for debugging evaulations and predictions among other things. \n",
    "\n",
    "There are also other callbacks available to use in the the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print (\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/363 [============================>.] - ETA: 0s - loss: 0.3299\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.3556\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                   validation_data=(X_valid,y_valid),\n",
    "                   callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "Comes pre-installed. Can:\n",
    "- View the learning curves while training\n",
    "- compare learning curves between multiple runs\n",
    "- visualize the computation graph\n",
    "- analyze training stats\n",
    "- view images generated by the model\n",
    "- visualize complex multidimensional data projected down to 3D and auto clutered\n",
    "- and more!\n",
    "\n",
    "Requires the program output to a special binary log file called an *event file*. Each binary data record is called a *summary*. The Tensorboard server that gets started up will watch the log directory and auto update the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2020_08_26-08_46_21'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = \"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation = \"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer= keras.optimizers.SGD(lr=1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 7.8215WARNING:tensorflow:From /opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 10s - loss: 7.0195WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0617s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%python3` not found (But cell magic `%%python3` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%python3 -m tensorboard.main --logdir=./my_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2020_08_27-06_25_56'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2= get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 7.8215WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0338s). Check your callbacks.\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5530 - val_loss: 302.8536\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 5292745216.0000 - val_loss: 1.3230\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3411 - val_loss: 1.3176\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3423 - val_loss: 1.3261\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3423 - val_loss: 1.3154\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3431 - val_loss: 1.3203\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3425 - val_loss: 1.3149\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3433 - val_loss: 1.3157\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3435 - val_loss: 1.3150\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3423 - val_loss: 1.3172\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3432 - val_loss: 1.3174\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3426 - val_loss: 1.3150\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3422 - val_loss: 1.3270\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3430 - val_loss: 1.3195\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3426 - val_loss: 1.3157\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3422 - val_loss: 1.3182\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3429 - val_loss: 1.3223\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3422 - val_loss: 1.3154\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3421 - val_loss: 1.3168\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3430 - val_loss: 1.3151\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3418 - val_loss: 1.3174\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3424 - val_loss: 1.3204\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3420 - val_loss: 1.3164\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3429 - val_loss: 1.3157\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3422 - val_loss: 1.3180\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.3425 - val_loss: 1.3195\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3422 - val_loss: 1.3157\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3425 - val_loss: 1.3222\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3431 - val_loss: 1.3267\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3424 - val_loss: 1.3174- ETA: 0s - loss: \n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                               save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3,\n",
    "               input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse',optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.1971 - val_loss: 1.7696\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6045 - val_loss: 0.5361\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 0.5093\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.4392\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.4161\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4036\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.3930\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.3925\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.3853\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.3835\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.3895\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.3862\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.3989\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3874\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.3781\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.3754\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3953\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3955\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3856\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4188\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3913\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.4175\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3698\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3932\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.4069\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 0.4034\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3677\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3717 - val_loss: 0.4000\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.3803\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3691 - val_loss: 0.4083\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3743\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.4083\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3732\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.3840\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.4044\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3549\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3838\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3637\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3606\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3765\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3957\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.4018\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3826\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.3986\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.3525\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3485\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3852\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3813\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3598\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3408\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.4100\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3490 - val_loss: 0.3343\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.4641\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3390\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3613\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3383\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.3304\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.4402\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3700\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3538\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3503\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3938\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.3307\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3567\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3514\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.3267\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.3413\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3718\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.4790\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3763\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3852\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.3637\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.5490\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3387 - val_loss: 0.3623\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e486860>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 841us/step - loss: 0.3421\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d9dbbdbf9a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_new' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 3.5557 - val_loss: 1.8752\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3347 - val_loss: 0.9522\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8591 - val_loss: 0.7820\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7360 - val_loss: 0.7249\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6930 - val_loss: 0.6994\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6668 - val_loss: 0.9118\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6514 - val_loss: 0.8495\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6381 - val_loss: 0.8605\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6276 - val_loss: 0.6524\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.8619\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6057 - val_loss: 0.8659\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.5962\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5859 - val_loss: 0.9062\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5828 - val_loss: 0.9541\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.6402\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.7806\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - val_loss: 0.7985\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - val_loss: 0.8756\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 0.8958\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5564 - val_loss: 0.8657\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5559 - val_loss: 0.5940\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.8007\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.7792\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5459 - val_loss: 0.7622\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5453 - val_loss: 0.6476\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5431 - val_loss: 0.5424\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5373 - val_loss: 0.8687\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5424 - val_loss: 0.5390\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5365 - val_loss: 0.7179\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5384 - val_loss: 0.6029\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5362 - val_loss: 0.5947\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5305\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.6601\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5341 - val_loss: 0.6326\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.5072\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.7270\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 0.5055\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5284 - val_loss: 0.7985\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5338 - val_loss: 0.5176\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5823\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.7114\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5059\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5302 - val_loss: 0.5008\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5274 - val_loss: 0.7397\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5309 - val_loss: 0.6169\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5303 - val_loss: 0.5264\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.6916\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5298 - val_loss: 0.6554\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 0.6607\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 0.8497\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5310 - val_loss: 0.6664\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5996\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.6414\n",
      "121/121 [==============================] - 0s 902us/step - loss: 0.5368\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=  20.6s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5605 - val_loss: 23.0855\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4777 - val_loss: 10.8387\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0149 - val_loss: 4.4392\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8729 - val_loss: 1.5338\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8027 - val_loss: 0.7192\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7542 - val_loss: 1.2046\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7160 - val_loss: 2.4524\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6847 - val_loss: 4.1421\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6588 - val_loss: 5.9820\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6371 - val_loss: 7.7654\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6187 - val_loss: 9.6230\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6029 - val_loss: 11.3609\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5896 - val_loss: 12.9821\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5781 - val_loss: 14.2266\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - val_loss: 15.4321\n",
      "121/121 [==============================] - 0s 713us/step - loss: 0.9198\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=   5.3s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.2972 - val_loss: 1.3307\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9648 - val_loss: 0.6934\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.5469\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5468 - val_loss: 0.7322\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5372 - val_loss: 0.4963\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5539\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5320 - val_loss: 0.5729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.7873\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5968\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.4951\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5286 - val_loss: 0.7591\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5368\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.4968\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5778\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5117\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.7055\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5320 - val_loss: 0.5399\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5307 - val_loss: 0.5257\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.7902\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5327 - val_loss: 0.5852\n",
      "121/121 [==============================] - 0s 857us/step - loss: 0.5317\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=   7.0s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4256 - val_loss: 66.5657\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9941 - val_loss: 137.1489\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2587 - val_loss: 716.1609\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3545 - val_loss: 2297.8599\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 17.0750 - val_loss: 9988.3369\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 198.7058 - val_loss: 39231.9727\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 424.9946 - val_loss: 155196.9375\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2992.7771 - val_loss: 612492.9375\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7662.3345 - val_loss: 2435756.7500\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 53693.9609 - val_loss: 10128971.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 135638.0156 - val_loss: 39694556.0000\n",
      "121/121 [==============================] - 0s 864us/step - loss: 105477.5781\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   4.0s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1573 - val_loss: 23.1193\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5349 - val_loss: 22.1675\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 22.3752\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5148 - val_loss: 21.3891\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5108 - val_loss: 20.8855\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5082 - val_loss: 20.6379\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 20.0736\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 20.7178\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5029 - val_loss: 20.0844\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5032 - val_loss: 17.0622\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5036 - val_loss: 19.1666\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5017 - val_loss: 20.8246\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5023 - val_loss: 22.0298\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5049 - val_loss: 17.6022\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5024 - val_loss: 18.6171\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5024 - val_loss: 20.0451\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 17.5898\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 17.4526\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 19.5015\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 17.3223\n",
      "121/121 [==============================] - 0s 740us/step - loss: 0.9327\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   8.9s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4616 - val_loss: 0.5742\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6113 - val_loss: 6.7367\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5784 - val_loss: 6.5227\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5820 - val_loss: 19.7083\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6738 - val_loss: 205.7215\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6846 - val_loss: 282.6048\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5718 - val_loss: 656.3251\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12.3829 - val_loss: 1380.0117\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 14.8443 - val_loss: 2817.4534\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.4320 - val_loss: 4499.3799\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 121.3308 - val_loss: 8457.8672\n",
      "121/121 [==============================] - 0s 719us/step - loss: 11.0521\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   3.8s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.5089 - val_loss: 2.6033\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0793 - val_loss: 1.0424\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8038 - val_loss: 0.7507\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7203 - val_loss: 0.6758\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6785 - val_loss: 0.6484\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6498 - val_loss: 0.6241\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6261 - val_loss: 0.6073\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6055 - val_loss: 0.5826\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5870 - val_loss: 0.5597\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5445\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5547 - val_loss: 0.5314\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5147\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 0.5030\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5159 - val_loss: 0.4904\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.4791\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4948 - val_loss: 0.4695\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.4608\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4524\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4476\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4383\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4355\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4282\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4437 - val_loss: 0.4230\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4384 - val_loss: 0.4166\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.4161\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4142\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4100\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4217 - val_loss: 0.4132\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4103\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4149 - val_loss: 0.4032\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.3964\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.3956\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4013\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4004\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.3913\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3986\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.3871\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.3998\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3858\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3967\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3918\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3866\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3800\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3997\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3861\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3805\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3919\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3826\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3812\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.3905\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3832\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3827\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3859\n",
      "121/121 [==============================] - 0s 735us/step - loss: 0.3865\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  19.2s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7762 - val_loss: 17.5435\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1017 - val_loss: 15.4502\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8039 - val_loss: 11.1084\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7051 - val_loss: 8.0885\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6575 - val_loss: 6.1076\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 4.7302\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6007 - val_loss: 3.6783\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 2.8274\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 2.2526\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5433 - val_loss: 1.7966\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5284 - val_loss: 1.4646\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5153 - val_loss: 1.1656\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5036 - val_loss: 0.9599\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.8400\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4839 - val_loss: 0.7148\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.6408\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.5679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4612 - val_loss: 0.5264\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4549 - val_loss: 0.4894\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4711\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4442 - val_loss: 0.4525\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4467\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4404\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4302\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4284\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.4270\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4269\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.4416\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.4363\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4330\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4408\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4484\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4647\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4789\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4746\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4974\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.5135\n",
      "121/121 [==============================] - 0s 833us/step - loss: 0.4088\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  15.0s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.8501 - val_loss: 2.0961\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1187 - val_loss: 1.2079\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8431 - val_loss: 0.8075\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7630 - val_loss: 0.7207\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7220 - val_loss: 0.6952\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6925 - val_loss: 0.6614\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6677 - val_loss: 0.6378\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6461 - val_loss: 0.6132\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6268 - val_loss: 0.6043\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6081 - val_loss: 0.5937\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5908 - val_loss: 0.5658\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 0.5551\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5601 - val_loss: 0.5476\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5465 - val_loss: 0.5450\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5340 - val_loss: 0.5314\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5067\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5119 - val_loss: 0.4983\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5020 - val_loss: 0.4873\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4930 - val_loss: 0.4748\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4849 - val_loss: 0.4767\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4771 - val_loss: 0.4719\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4701 - val_loss: 0.4623\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4637 - val_loss: 0.4640\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4575 - val_loss: 0.4777\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4521 - val_loss: 0.4488\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4475\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4420\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4449\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4581\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4385\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4226\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.4458\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4201 - val_loss: 0.4242\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4174 - val_loss: 0.4542\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.4279\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.4341\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 0.4189\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4078 - val_loss: 0.4344\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.4235\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.4183\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4552\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4411\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4073\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4294\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4238\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.4128\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3977\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.4028\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.4362\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4235\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 0.4171\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3859 - val_loss: 0.4273\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.4076\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3885\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.4003\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4176\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4201\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4177\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4166\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.3910\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.4094\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.4363\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4025\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.4028\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3737\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  26.3s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4720 - val_loss: 7.9722\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1323 - val_loss: 5.6563\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8832 - val_loss: 4.1443\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8066 - val_loss: 3.1169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7657 - val_loss: 2.6199\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7374 - val_loss: 2.2830\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7171 - val_loss: 1.9726\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6983 - val_loss: 1.7536\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6816 - val_loss: 1.5653\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6663 - val_loss: 1.4316\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6521 - val_loss: 1.3165\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6387 - val_loss: 1.2101\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6261 - val_loss: 1.1236\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 1.0591\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.9875\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5910 - val_loss: 0.9345\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5804 - val_loss: 0.8832\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5701 - val_loss: 0.8424\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5602 - val_loss: 0.8079\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5511 - val_loss: 0.7646\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5420 - val_loss: 0.7347\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5332 - val_loss: 0.7075\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.6815\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.6537\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.6360\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 0.6174\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4952 - val_loss: 0.6010\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4887 - val_loss: 0.5887\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4824 - val_loss: 0.5778\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4766 - val_loss: 0.5671\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4710 - val_loss: 0.5557\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4658 - val_loss: 0.5475\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4608 - val_loss: 0.5403\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4561 - val_loss: 0.5321\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4516 - val_loss: 0.5250\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4476 - val_loss: 0.5165\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.5106\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.5053\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.5004\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4966\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4922\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 0.4891\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4850\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4220 - val_loss: 0.4854\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4828\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4173 - val_loss: 0.4779\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 0.4783\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.4755\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4766\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4093 - val_loss: 0.4753\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.4714\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.4726\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4043 - val_loss: 0.4722\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4708\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4704\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.4714\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4704\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.4718\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4712\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4701\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.4718\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.4717\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4704\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4735\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.4738\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4729\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.4716\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.4731\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4720\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.4721\n",
      "121/121 [==============================] - 0s 815us/step - loss: 0.4001\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  27.9s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.7641 - val_loss: 28.0492\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0504 - val_loss: 43.0472\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6124 - val_loss: 37.0128\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3603 - val_loss: 28.7538\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1689 - val_loss: 20.6120\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0259 - val_loss: 14.6245\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9261 - val_loss: 10.5960\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8594 - val_loss: 7.2861\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8137 - val_loss: 5.1836\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7810 - val_loss: 3.7344\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7555 - val_loss: 2.7778\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7346 - val_loss: 1.9391\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7165 - val_loss: 1.4673\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7002 - val_loss: 1.2321\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6852 - val_loss: 0.9812\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6712 - val_loss: 0.8534\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6583 - val_loss: 0.7166\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6459 - val_loss: 0.6424\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6340 - val_loss: 0.5949\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.5764\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6116 - val_loss: 0.5809\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6027\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5911 - val_loss: 0.6369\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5816 - val_loss: 0.6922\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.7604\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.8304\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5555 - val_loss: 0.8810\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5477 - val_loss: 0.9624\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5401 - val_loss: 0.9578\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5332 - val_loss: 1.0158\n",
      "121/121 [==============================] - 0s 784us/step - loss: 0.5490\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  10.9s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9218 - val_loss: 4.3285\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2869 - val_loss: 2.8653\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9733 - val_loss: 1.8260\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8526 - val_loss: 1.2974\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7870 - val_loss: 0.9606\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7448 - val_loss: 0.7924\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7141 - val_loss: 0.7158\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6902 - val_loss: 0.6616\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6699 - val_loss: 0.6363\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6525 - val_loss: 0.6160\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 0.5999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6216 - val_loss: 0.5855\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6084 - val_loss: 0.5729\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.5615\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5844 - val_loss: 0.5509\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5739 - val_loss: 0.5399\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5641 - val_loss: 0.5301\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.5210\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5461 - val_loss: 0.5129\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5381 - val_loss: 0.5062\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.4992\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.4932\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5169 - val_loss: 0.4875\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5106 - val_loss: 0.4857\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.4783\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4996 - val_loss: 0.4746\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4945 - val_loss: 0.4700\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4897 - val_loss: 0.4676\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.4687\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.4618\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.4607\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.4630\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.4583\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4663 - val_loss: 0.4643\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4591\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4603 - val_loss: 0.4562\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4576 - val_loss: 0.4539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4547\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4525 - val_loss: 0.4534\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4502 - val_loss: 0.4523\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.4613\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4593\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.4497\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 0.4544ETA: 0s - loss: 0.445\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.4533\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.4497\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4470\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4470\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4532\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4549\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4534\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4594\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4535\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4484\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4489\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4465\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4232 - val_loss: 0.4489\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4514\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4499\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4441\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4476\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4501\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.4432\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.4385\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.4381\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4440\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4354\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4381\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4341\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4395\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4340\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4407\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4309\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4328\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4349\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4346\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4339\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.4333\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.4281\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4354\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4322\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4299\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4292\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.4342\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4219\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4290\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.4329\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.4306\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4337\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4251\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4237\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.4191\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.4238\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.4203\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4209\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.4215\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4251\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4161\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.4199\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.4242\n",
      "121/121 [==============================] - 0s 761us/step - loss: 0.3897\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  38.5s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1013 - val_loss: 5.2312\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8603 - val_loss: 26.5013\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7494 - val_loss: 40.6122\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0991 - val_loss: 135.6917\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3388 - val_loss: 237.1149\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6734 - val_loss: 506.5569\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0735 - val_loss: 1165.5585\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 19.0953 - val_loss: 2646.9749\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 28.1002 - val_loss: 5780.9756\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 97.2631 - val_loss: 13751.4180\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 159.4888 - val_loss: 31633.9141\n",
      "121/121 [==============================] - 0s 760us/step - loss: 81.5957\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   3.5s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4769 - val_loss: 14.0701\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 16.8410\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5493 - val_loss: 19.0635\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5365 - val_loss: 19.7342\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 20.0593\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 20.2376\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5153 - val_loss: 20.0296\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 20.3793\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 20.1103\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 18.4892\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 19.4013\n",
      "121/121 [==============================] - 0s 733us/step - loss: 0.9640\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   3.5s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0333 - val_loss: 13.7380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6240 - val_loss: 10.0594\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7131 - val_loss: 41.2693\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1121 - val_loss: 74.9048\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9784 - val_loss: 205.5686\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9726 - val_loss: 246.7374\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5115 - val_loss: 388.8352\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.9673 - val_loss: 620.5344\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.9990 - val_loss: 919.7242\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1843 - val_loss: 1082.5527\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 21.4948 - val_loss: 1471.0372\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10.2613 - val_loss: 1957.3093\n",
      "121/121 [==============================] - 0s 662us/step - loss: 2.0491\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   3.8s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2457 - val_loss: 22.8634\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1255 - val_loss: 36.5661\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9314 - val_loss: 304.7440\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8113 - val_loss: 71.4702\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8365 - val_loss: 312.6021\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8876 - val_loss: 0.4035\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.3815\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3614\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.3613\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3455\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3469\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3554\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3456\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.3430\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3427\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3421\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3402\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3426\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3416\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3385\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3428\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.3400\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3584\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3509\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3590\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3456\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3546\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3542\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.3522\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3408\n",
      "121/121 [==============================] - 0s 708us/step - loss: 0.3580\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=   9.3s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8950 - val_loss: 3.0949\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.4712\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4610 - val_loss: 0.4231\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4021\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4323\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.6513\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.8508\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 1.0201\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 1.1757\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.8698\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.9377\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 1.0793\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 1.1923\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 1.1186\n",
      "121/121 [==============================] - 0s 737us/step - loss: 0.4037\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=   4.6s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9047 - val_loss: 1.2874\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4870 - val_loss: 0.7809\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 1.8555\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5436 - val_loss: 18.7095\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 78.6924\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8047 - val_loss: 0.4362\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.3913\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4218\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.4237\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.3656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4488\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3706\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3624\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4259\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3565\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.4250\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3505\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.4285\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3458\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3817\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3408\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3550\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.4301\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3363\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3482\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.4181\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3566 - val_loss: 0.3341\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3680\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3554\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3432\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.4889\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.3439\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3471 - val_loss: 0.4453\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3286\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3491\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3439 - val_loss: 0.3309\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.3275\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.3267\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.4576\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3242\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3376 - val_loss: 0.6091\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.3217\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3504\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3561\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.4243\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3171\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3261\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.4461\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.3319\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.5067\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3640\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3154\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.3790\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3139\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3709\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3641\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3207\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3252 - val_loss: 0.4157\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3098\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3260\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3305\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.3103\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3241 - val_loss: 0.4051\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3067\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3350\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3099\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.3082\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3138\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.4052\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.3043\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.3432\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.3366\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3071\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.4425\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.4489\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3102\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3665\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3031\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3678\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3040\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.3673\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.3110\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.4228\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3015\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3384\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3726\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3027\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3149 - val_loss: 0.4641\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3008\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3138 - val_loss: 0.3173\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3010\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3385\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.4416\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3790\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.5682\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3435\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.3789\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.4178\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3133 - val_loss: 0.3502\n",
      "121/121 [==============================] - 0s 743us/step - loss: 0.3168\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=  35.3s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.0446 - val_loss: 7.0502\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3108 - val_loss: 7.2037\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6259 - val_loss: 5.5884\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3383 - val_loss: 3.7640\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1769 - val_loss: 2.5552\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0669 - val_loss: 2.0914\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9873 - val_loss: 1.6989\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9225 - val_loss: 1.4173\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8695 - val_loss: 1.2066\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8251 - val_loss: 1.0479\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7880 - val_loss: 0.9248\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7571 - val_loss: 0.8264\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7314 - val_loss: 0.7581\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7096 - val_loss: 0.7119\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6917 - val_loss: 0.6743\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6760 - val_loss: 0.6514\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6629 - val_loss: 0.6371\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6514 - val_loss: 0.6283\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.6229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6322 - val_loss: 0.6221\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6241 - val_loss: 0.6180\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6164 - val_loss: 0.6178\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6150\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6023 - val_loss: 0.6175\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.6112\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5900 - val_loss: 0.6049\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5840 - val_loss: 0.6013\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5783 - val_loss: 0.5932\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.5873\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5833\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5619 - val_loss: 0.5789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5567 - val_loss: 0.5713\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5516 - val_loss: 0.5664\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5467 - val_loss: 0.5614\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.5537\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5371 - val_loss: 0.5536\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5326 - val_loss: 0.5419\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 0.5418\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 0.5343\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5282\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5153 - val_loss: 0.5252\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 0.5198\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5159\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5035 - val_loss: 0.5109\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4997 - val_loss: 0.5071\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4959 - val_loss: 0.5049\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4925 - val_loss: 0.4988\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.4950\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.4902\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.4869\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.4851\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4754 - val_loss: 0.4779\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4721 - val_loss: 0.4730\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4689 - val_loss: 0.4699\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.4657\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4629 - val_loss: 0.4605\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4583\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4571 - val_loss: 0.4528\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4496\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.4473\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.4437\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4411\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4392\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4341\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 0.4314\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.4299\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4275\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4327 - val_loss: 0.4236\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4217\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4202\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4168\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4144\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4125\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4105\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4085\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4071\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.4048\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4032\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.4017\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4002\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.3986\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.3973\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.3959\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4051 - val_loss: 0.3949\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.3931\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.3926\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.3914\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3897\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.3888\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.3880\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.3866\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3861\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3848\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3839\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.3836\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3840\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3822\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3806\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3822\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3796\n",
      "121/121 [==============================] - 0s 771us/step - loss: 0.3993\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=  35.2s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.0701 - val_loss: 2.9725\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1451 - val_loss: 5.9015\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2758 - val_loss: 10.8119\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0903 - val_loss: 11.3108\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0053 - val_loss: 9.9424\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9444 - val_loss: 8.2069\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8977 - val_loss: 6.6004\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8609 - val_loss: 4.8507\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8311 - val_loss: 3.5263\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8061 - val_loss: 2.6353\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7845 - val_loss: 1.9734\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7657 - val_loss: 1.4481\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7491 - val_loss: 1.1077\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7340 - val_loss: 0.8819\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7201 - val_loss: 0.7221\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7071 - val_loss: 0.6649\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6951 - val_loss: 0.6775\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6837 - val_loss: 0.7491\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6729 - val_loss: 0.8815\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6627 - val_loss: 1.0685\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6528 - val_loss: 1.3065\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6436 - val_loss: 1.5428\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6350 - val_loss: 1.8315\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6268 - val_loss: 2.1427\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6190 - val_loss: 2.5085\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 2.8640\n",
      "121/121 [==============================] - 0s 759us/step - loss: 0.6770\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=   9.0s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.4059 - val_loss: 3.5308\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5613 - val_loss: 3.0045\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4038 - val_loss: 2.5464\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9815 - val_loss: 1.8717\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8396 - val_loss: 1.3067\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7692 - val_loss: 0.9966\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7270 - val_loss: 0.8331\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6993 - val_loss: 0.7309\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6799 - val_loss: 0.6922\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6652 - val_loss: 0.6623\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6528 - val_loss: 0.6391\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6420 - val_loss: 0.6199\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6325 - val_loss: 0.6066\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 0.5952\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.5855\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.5761\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.5671\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5915 - val_loss: 0.5590\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5841 - val_loss: 0.5515\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5445\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5697 - val_loss: 0.5376\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.5308\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5559 - val_loss: 0.5241\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5491 - val_loss: 0.5179\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5425 - val_loss: 0.5114\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 0.5049\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.4989\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.4930\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5173 - val_loss: 0.4880\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5115 - val_loss: 0.4819\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.4768\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5003 - val_loss: 0.4726\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4951 - val_loss: 0.4680\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4901 - val_loss: 0.4647\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.4579\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.4552\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4523\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4503\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4651 - val_loss: 0.4481\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4616 - val_loss: 0.4479\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4464\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4442\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.4442\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4496 - val_loss: 0.4436\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4428\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4428\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4431\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4436\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4375 - val_loss: 0.4441\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4441\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4456\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4460\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4467\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4484\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4490\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4493\n",
      "121/121 [==============================] - 0s 740us/step - loss: 0.4256\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=  18.5s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3002 - val_loss: 38.2652\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9964 - val_loss: 0.6706\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.5520\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4986 - val_loss: 0.5090\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4710 - val_loss: 0.4813\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4761\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4565\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4321 - val_loss: 0.4533\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4502\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4210 - val_loss: 0.4389\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.4360\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4313\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.4253\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4228\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.4209\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4192\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4156\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4137\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4128\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.4104\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4101\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4070\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4080\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4037\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4030\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.4000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3972\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3974\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3943\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3948\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3922\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3917\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3905\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3893\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3876\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3916\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3831\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3875\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3846\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3842\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3814\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3808\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3834\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3804\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3824\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3798\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3705 - val_loss: 0.3800\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3783\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3797\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3820\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.3765\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3772\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3766\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3773\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.3754\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.3750\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3750\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3766\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.3749\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3764\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3759\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3736\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3750\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.3727\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3757\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3733\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3719\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3714\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.3698\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3689\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3717\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3699\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.3664\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3663\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3689\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.3670\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3682\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3647\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3669\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3654\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3639\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3644\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3632\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.3619\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3615\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.3592\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3633\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3581\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.3597\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3582\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3575\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.3572\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3582\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3579\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3626\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3564\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3560\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3618\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3552\n",
      "121/121 [==============================] - 0s 729us/step - loss: 0.3645\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=  30.1s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2613 - val_loss: 0.6451\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5785 - val_loss: 0.8942\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5115 - val_loss: 1.2421\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 1.2691\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4597 - val_loss: 0.9915\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 0.6535\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.5216\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4234 - val_loss: 0.4130\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.3818\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4044\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4355\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.4276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4761\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.5445\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.5613\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.6763\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.6692\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.7573\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.6834\n",
      "121/121 [==============================] - 0s 785us/step - loss: 0.3963\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=   6.9s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2040 - val_loss: 71.0120\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0541 - val_loss: 42.2913\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8661 - val_loss: 1.3112\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5287 - val_loss: 0.5968\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.4855\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.4448\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4217\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 0.4094\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4025\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.3958\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.3918\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4230 - val_loss: 0.3892\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.3915\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.3996\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.4076\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4218\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.4317\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.4354\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.4429\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.4453\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4460\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4415\n",
      "121/121 [==============================] - 0s 736us/step - loss: 0.3947\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=   7.4s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7.7197 - val_loss: 43.0907\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.5377 - val_loss: 27.4372\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0702 - val_loss: 17.4473\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0672 - val_loss: 11.0914\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3745 - val_loss: 7.0664\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8936 - val_loss: 4.5088\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5544 - val_loss: 2.9277\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3139 - val_loss: 1.9631\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1426 - val_loss: 1.3974\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0191 - val_loss: 1.0599\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9292 - val_loss: 0.8770\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8636 - val_loss: 0.7898\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8150 - val_loss: 0.7557\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7787 - val_loss: 0.7567\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7515 - val_loss: 0.7696\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7308 - val_loss: 0.7947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7148 - val_loss: 0.8231\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7022 - val_loss: 0.8540\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6920 - val_loss: 0.8834\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6838 - val_loss: 0.9089\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6772 - val_loss: 0.9189\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6713 - val_loss: 0.9382\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6664 - val_loss: 0.9536\n",
      "121/121 [==============================] - 0s 693us/step - loss: 0.6673\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=   7.3s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.6328 - val_loss: 25.5463\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.6957 - val_loss: 23.8232\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3247 - val_loss: 22.6165\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3439 - val_loss: 21.7670\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6347 - val_loss: 21.1673\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1177 - val_loss: 20.7451\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7380 - val_loss: 20.4552\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4573 - val_loss: 20.2628\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2483 - val_loss: 20.1364\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0921 - val_loss: 20.0567\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9744 - val_loss: 20.0180\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8854 - val_loss: 20.0099\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8177 - val_loss: 20.0241\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7659 - val_loss: 20.0459\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7259 - val_loss: 20.0826\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6949 - val_loss: 20.1289\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6707 - val_loss: 20.1804\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6517 - val_loss: 20.2376\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6366 - val_loss: 20.3030\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 20.3653\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6146 - val_loss: 20.4378\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6066 - val_loss: 20.5061\n",
      "121/121 [==============================] - 0s 757us/step - loss: 1.0973\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=   7.3s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.1564 - val_loss: 7.6683\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4886 - val_loss: 4.9412\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3699 - val_loss: 3.3299\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6029 - val_loss: 2.3535\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0673 - val_loss: 1.7864\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6878 - val_loss: 1.4390\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4151 - val_loss: 1.2303\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2174 - val_loss: 1.1115\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0734 - val_loss: 1.0396\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 0.9896\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8894 - val_loss: 0.9739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8312 - val_loss: 0.9570\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7875 - val_loss: 0.9426\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7545 - val_loss: 0.9414\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7294 - val_loss: 0.9351\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7100 - val_loss: 0.9457\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6951 - val_loss: 0.9437\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6832 - val_loss: 0.9404\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6737 - val_loss: 0.9554\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6661 - val_loss: 0.9559\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6596 - val_loss: 0.9558\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6543 - val_loss: 0.9576\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6496 - val_loss: 0.9476\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6455 - val_loss: 0.9447\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6419 - val_loss: 0.9405\n",
      "121/121 [==============================] - 0s 769us/step - loss: 0.6455\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=   8.6s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3724 - val_loss: 19.2760\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8289 - val_loss: 4.6055\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5845 - val_loss: 0.7004\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5034\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.4495\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4262\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4112\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4155\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.4120\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4010\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4074\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.3889\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3859\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4045\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.3846\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3960\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3611 - val_loss: 0.4089\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 0.3869\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.3831\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3541 - val_loss: 0.3809\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.3896\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3832\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.4091\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3679\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3796\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.3614\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3639\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.3727\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3736\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.3584\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3479\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3440\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3357\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3444\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.3285\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.3482\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3243\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3493\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3293 - val_loss: 0.3234\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 0.3429\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.3282\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3236\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.3246\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3410\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.3236\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3235 - val_loss: 0.3294\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.3368\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3236 - val_loss: 0.3343\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.3173\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.3414\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3386\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.3331\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3262\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3184\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3237\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3197\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3317\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3140 - val_loss: 0.3240\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.3102\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.3207\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3261\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3356\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3113\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3329\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3244\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3059\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3231\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3250\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3158\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3114\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.3195\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3120\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3045 - val_loss: 0.3047\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.3233\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.3002- ETA: 0s - loss: 0. - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3107\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3151\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3017\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3221\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3046\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3125\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.3010\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.3379\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.2980\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.3537\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.2976\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2968 - val_loss: 0.3239\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2969 - val_loss: 0.3021\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2967 - val_loss: 0.3215\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.2974\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2948 - val_loss: 0.3185\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2950 - val_loss: 0.2950\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2942 - val_loss: 0.3171\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2940 - val_loss: 0.2982\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.2946\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2927 - val_loss: 0.3052\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.2966\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.3231\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2914 - val_loss: 0.2903\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2908 - val_loss: 0.3540\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.2961\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3199\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  36.5s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2201 - val_loss: 0.8642\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.7994\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 1.0803\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 1.1494\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4606 - val_loss: 0.9498\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.6208\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4657\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.3888\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4084\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.4312\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.5341\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.6081\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.7209\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.8821\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.9049\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.9792\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.9532\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 1.0397\n",
      "121/121 [==============================] - 0s 795us/step - loss: 0.3909\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=   7.1s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1300 - val_loss: 2.2824\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6910 - val_loss: 2.5063\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5904 - val_loss: 1.3345\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 1.8303\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4879 - val_loss: 1.1690\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 1.0937\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.5393\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.5528\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.4217\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.3978\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.7642\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.3953\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3690\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.6782\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.5137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 1.5716\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 1.5438\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 2.5256\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 1.2077\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.8839\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.3408\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3590 - val_loss: 0.3928\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3411\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.4823\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3589\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3810\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.4593\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3500 - val_loss: 0.3360\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.4983\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3747\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.4128\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.5465\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3826\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.5040\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3434 - val_loss: 0.3439\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3398 - val_loss: 0.4821\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3595\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.6279\n",
      "121/121 [==============================] - 0s 902us/step - loss: 0.3388\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  14.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x110329208>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a6157f209a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m rnd_search_cv.fit(X_train,y_train,epochs=100,\n\u001b[1;32m     13\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 762\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x110329208>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\" : np.arange(1,100),\n",
    "    \"learning_rate\" : reciprocal(3e-4,3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs,\n",
    "                                  n_iter=10,cv=3,verbose=2)\n",
    "rnd_search_cv.fit(X_train,y_train,epochs=100,\n",
    "                 validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.34988949696222943"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f89828bd4b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like there is some issue here when using Keras \n",
    "# as a wrapper and RandomizedSearchCV. It wont let \n",
    "# you use many of RSC's abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Exercises\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_full[0], cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid, X_train = X_train_full[:6000] / 255., X_train_full[6000:] / 255.\n",
    "y_train_valid, y_train = y_train_full[:6000], y_train_full[6000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2717 - accuracy: 0.9193 - val_loss: 0.1542 - val_accuracy: 0.9542\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1115 - accuracy: 0.9668 - val_loss: 0.0866 - val_accuracy: 0.9743\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9771 - val_loss: 0.0969 - val_accuracy: 0.9688\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0535 - accuracy: 0.9834 - val_loss: 0.0791 - val_accuracy: 0.9752\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0393 - accuracy: 0.9879 - val_loss: 0.0805 - val_accuracy: 0.9748\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.0727 - val_accuracy: 0.9793\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0717 - val_accuracy: 0.9798\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0751 - val_accuracy: 0.9800\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0699 - val_accuracy: 0.9815\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0722 - val_accuracy: 0.9810\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0733 - val_accuracy: 0.9813\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0716 - val_accuracy: 0.9817\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0737 - val_accuracy: 0.9817\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0714 - val_accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.SGD(lr=1e-1),\n",
    "              metrics= [\"accuracy\"]\n",
    "             )\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                   validation_data = (X_train_valid, y_train_valid),\n",
    "                   callbacks = [keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06646956503391266, 0.9824000000953674]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
